# Learning DNN IP Protection
[![Stars](https://img.shields.io/github/stars/TracyCuiq/Learning-Deep-Hiding)](.) [![Page Views Count](https://badges.toozhao.com/badges/01J03VTSD77W9K74THJ7QRXHF2/green.svg)](.)

This repo collects the paper list of *DNN IP Protection*.
I have compiled summaries of various papers and organized them into categories. Please feel free to contribute by submitting pull requests!

##### ![](https://img.shields.io/badge/Watermarking-White_box-white)
- [2022/08] **[Move: Effective and harmless ownership verification via embedded external features](https://arxiv.org/pdf/2208.02820)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Move%3A+Effective+and+harmless+ownership+verification+via+embedded+external+features&btnG=)  
- [2022/06] **[Defending against model stealing via verifying embedded external features](https://ojs.aaai.org/index.php/AAAI/article/view/20036/19795)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Defending+against+model+stealing+via+verifying+embedded+external+features&btnG=) ![](https://img.shields.io/badge/AAAI_2022-f1b800) 
- [2021/07] **[Watermarking Deep Neural Networks with Greedy Residuals](https://openreview.net/pdf?id=8FUlWs8cLq)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Watermarking+deep+neural+networks+with+greedy+residuals&btnG=) ![](https://img.shields.io/badge/ICLR_2021-f1b800) 
- [2021/04] **[Riga: Covert and robust white-box watermarking of deep neural networks](https://arxiv.org/pdf/1910.14268)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Riga%3A+Covert+and+robust+white-box+watermarking+of+deep+neural+networks&btnG=) ![](https://img.shields.io/badge/WWW_2021-f1b800) 
- [2021] **[You are caught stealing my winning lottery ticket! making a lottery ticket claim its ownership](https://proceedings.neurips.cc/paper_files/paper/2021/file/0dfd8a39e2a5dd536c185e19a804a73b-Paper.pdf)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=You+are+caught+stealing+my+winning+lottery+ticket%21+making+a+lottery+ticket+claim+its+ownership&btnG=) ![](https://img.shields.io/badge/NeurIPS_2021-f1b800) 
- [2021] **[NeuNAC: A novel fragile watermarking algorithm for integrity protection of neural networks](https://www.sciencedirect.com/science/article/pii/S0020025521006642)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Neunac%3A+A+novel+fragile+watermarking+algorithm+for+integrity+protection+of+neural+networks&btnG=) ![](https://img.shields.io/badge/Information_Sciences-f1b800) 
- [2020/10] **[Reversible watermarking in deep convolutional neural networks for integrity authentication](https://arxiv.org/pdf/2104.04268)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Reversible+watermarking+in+deep+convolutional+neural+networks+for+integrity+authentication&btnG=) ![](https://img.shields.io/badge/MM_2020-f1b800) 
- [2019/06] **[DeepAttest: An end-to-end attestation framework for deep neural networks](https://dl.acm.org/doi/pdf/10.1145/3307650.3322251)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Deepattest%3A+an+end-to-end+attestation+framework+for+deep+neural+networks%2C%E2%80%9D&btnG=) ![](https://img.shields.io/badge/ISCA_2019-f1b800) 
- [2019/04] **[Deepsigns: An end-to-end watermarking framework for ownership protection of deep neural networks](https://dl.acm.org/doi/pdf/10.1145/3297858.3304051)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?lookup=0&q=Deepsigns:+an+end-to-end+watermarking+framework+for+protecting+the+ownership+of+deep+neural+networks&hl=en&as_sdt=0,5) ![](https://img.shields.io/badge/ASPLOS_2019-f1b800) 
- [2019/06] **[Deepmarks: A secure fingerprinting framework for digital rights management of deep learning models](https://dl.acm.org/doi/pdf/10.1145/3323873.3325042)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Deepmarks%3A+A+secure+fingerprinting+framework+for+digital+rights+management+of+deep+learning+models&btnG=) ![](https://img.shields.io/badge/ICMR_2019-f1b800) 
- [2017/06] **[Embedding watermarks into deep neural networks](https://dl.acm.org/doi/abs/10.1145/3078971.3078974)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/google-scholar.svg" alt="Code" width="20" height="20">](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Embedding+watermarks+into+deep+neural+networks&btnG=) ![](https://img.shields.io/badge/ICMR_2017-f1b800) 


##### ![](https://img.shields.io/badge/Watermarking-Black_box-white)
